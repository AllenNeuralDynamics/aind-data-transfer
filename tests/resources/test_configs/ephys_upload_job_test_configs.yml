# Leave values blank to use defaults
endpoints:
  raw_data_dir: tests/resources/v0.6.x_neuropixels_multiexp_multistream
  dest_data_dir: tests/resources/new/v0.6.x_neuropixels_multiexp_multistream
  s3_bucket: aind-transfer-test
  s3_prefix: # Defaults to folder in temp_data_dir name
  gcp_bucket: aind-data-dev
  gcp_prefix: test_20221001
  codeocean_domain: https://acmecorp.codeocean.com
  metadata_schemas: https://raw.githubusercontent.com/AllenNeuralDynamics/data_schema/main/schemas
  code_repo_location: https://github.com/AllenNeuralDynamics/aind-data-transfer
jobs: # Select which jobs to run
  clip: true
  compress: true
  attach_metadata: true
  upload_to_s3: true
  upload_to_gcp: true
  register_to_codeocean: false
  trigger_codeocean_spike_sorting: false
data:
  name: openephys
clip_data_job:
  clip_kwargs:
    n_frames:
compress_data_job:
  write_kwargs: {"n_jobs": -1, "chunk_duration": "1s", "progress_bar": true}
  format_kwargs:
    output_format:
  compressor:
    compressor_name: blosc
    kwargs: {"shuffle": "BITSHUFFLE"}
  scale_params:
    num_chunks_per_segment:
    chunk_size: 20
    disable_tqdm:
upload_data_job:
  dryrun: true # Set this to true to perform a dryrun of the upload
register_on_codeocean_job:
  tags: ['ecephys', 'raw']
  asset_name:  # Defaults to s3_prefix
  mount:  # Defaults to s3_prefix
trigger_codeocean_spike_sorting_job:
  asset_id: # Will try to resolve it if the register_on_codeocean_job is run
  mount:  # Defaults to s3_prefix
  capsule_id:
logging:
  level: "INFO" # Will override with env variable LOG_LEVEL
  file:  # If blank, will log to stdout.
