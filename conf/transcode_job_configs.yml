# Leave values blank to use defaults
endpoints:
  raw_data_dir:
  dest_data_dir:
  metadata_schemas:
  metadata_service_url:
  code_repo_location:
jobs: # Select which jobs to run
  upload_aux_files: true
  transcode: true
  create_ng_link: true
  create_metadata: true
data:
  name: exaspim
  subject_id:  # required
transcode_job:
  compressor:
    compressor_name: blosc
    kwargs: {cname: "zstd", clevel: 1, shuffle: "SHUFFLE"}
  chunk_size: 64  # MB
#  chunk_shape: [1, 1, 512, 256, 256]  # remove this field if you want automatic chunking
  resume: false  # resume processing if previous job failed
  n_levels: 8
  voxsize:
  exclude: []
  submit_args: {
    nodes: 1,
    ntasks_per_node: 32,
    cpus_per_task: 1,
    mem_per_cpu: 3000,  # MB
    conda_activate: ~,
    conda_env: ~,
    run_parent_dir: ~,
    walltime: "1-00:00:00",
    tmp_space: "8GB",  # this is per node
    mail_user: ~,
    queue: ~
  }
create_ng_link_job:
  vmin: 0
  vmax: 1000